{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Pytorch Modules for Training Models for sequential data\n",
    "output-file: learner.html\n",
    "title: Learner\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp learner\n",
    "#| default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from seqdata.core import *\n",
    "from seqdata.models.core import *\n",
    "from fastai.basics import *\n",
    "from fastai.callback.progress import *\n",
    "from fastai.callback.tracker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = DataBlock(blocks=(SequenceBlock.from_hdf(['current','voltage'],TensorSequencesInput,clm_shift=[-1,-1]),\n",
    "                        SequenceBlock.from_hdf(['voltage'],TensorSequencesOutput,clm_shift=[1])),\n",
    "                 get_items=CreateDict([DfHDFCreateWindows(win_sz=1000+1,stp_sz=1000,clm='current')]),\n",
    "                 splitter=ApplyToDict(ParentSplitter()))\n",
    "db = seq.dataloaders(get_hdf_files('test_data/battery/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.963240</td>\n",
       "      <td>12.116003</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SimpleRNN(2,1)\n",
    "lrn = Learner(db,model,loss_func=nn.MSELoss()).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GradientClipping(Callback):\n",
    "    \"`Callback` cutts of the gradient of every minibtch at `clip_val`\"\n",
    "    def __init__(self, clip_val=10): self.clip_val = clip_val\n",
    "\n",
    "    def after_backward(self):\n",
    "        nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.359455</td>\n",
       "      <td>11.462593</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SimpleRNN(2,1)\n",
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=GradientClipping(10)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GradientNormPrint(Callback):\n",
    "    \"`Callback` prints the norm of the gradient of every minibtch\"\n",
    "    # def __init__(self, clip_val=10): self.clip_val = clip_val\n",
    "\n",
    "    def before_step(self):\n",
    "        grads = [\n",
    "            param.grad.detach().flatten()\n",
    "            for param in self.model.parameters()\n",
    "            if param.grad is not None\n",
    "        ]\n",
    "        norm = torch.cat(grads).norm()\n",
    "        # print(f'Gradient norm: {norm:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.783390</td>\n",
       "      <td>11.957490</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 9.97\n",
      "Gradient norm: 9.97\n",
      "Gradient norm: 9.76\n",
      "Gradient norm: 9.86\n",
      "Gradient norm: 9.80\n",
      "Gradient norm: 10.00\n",
      "Gradient norm: 9.86\n",
      "Gradient norm: 10.01\n"
     ]
    }
   ],
   "source": [
    "model = SimpleRNN(2,1)\n",
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=GradientNormPrint()).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GradientBatchFiltering(Callback):\n",
    "    \"`Callback` skips batches with a gradient norm larger than `filter_val`\"\n",
    "    def __init__(self, filter_val=10): self.filter_val = filter_val\n",
    "\n",
    "    def before_step(self):\n",
    "        grads = [\n",
    "            param.grad.detach().flatten()\n",
    "            for param in self.model.parameters()\n",
    "            if param.grad is not None\n",
    "        ]\n",
    "        norm = torch.cat(grads).norm()\n",
    "        if norm > self.filter_val:\n",
    "            self.opt.zero_grad()\n",
    "            # print(f'Gradient norm: {norm:.2f} filtered')\n",
    "            raise CancelBatchException()\n",
    "        # print(f'Gradient norm: {norm:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11.226078</td>\n",
       "      <td>10.853340</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm: 11.20 filtered\n",
      "Gradient norm: 11.13 filtered\n",
      "Gradient norm: 11.09 filtered\n",
      "Gradient norm: 11.08 filtered\n"
     ]
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=GradientBatchFiltering(11.0)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class WeightClipping(Callback):\n",
    "    \"`Callback` that clips the weights of a given module at `clip_limit` after every iteration\"\n",
    "    def __init__(self, module, clip_limit = 1):\n",
    "        self.module = module\n",
    "        self.clip_limit = clip_limit\n",
    "\n",
    "    def after_batch(self):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        for p in self.module.parameters():\n",
    "            p.data.clamp_(-self.clip_limit,self.clip_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.616420</td>\n",
       "      <td>11.732989</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SimpleRNN(2,1)\n",
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=WeightClipping(model,clip_limit=1)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SkipFirstNCallback(Callback):\n",
    "    \"`Callback` skips first n samples from prediction and target, optionally `with_loss`\"\n",
    "    def __init__(self, n_skip = 0):\n",
    "        self.n_skip = n_skip\n",
    "\n",
    "    def after_pred(self):\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                dl = self.learn.dls.train\n",
    "                if (hasattr(dl,'rnn_reset') and dl.rnn_reset) or not hasattr(dl,'rnn_reset'): # if tbptt is used, only skip loss in the first minibatch\n",
    "                    self.learn.pred = self.pred[:,self.n_skip:]\n",
    "            #         import pdb; pdb.set_trace()\n",
    "                    if isinstance(self.yb, tuple):\n",
    "                        self.learn.yb = tuple([y[:,self.n_skip:] for y in self.yb])\n",
    "                    else:\n",
    "                        self.learn.yb = self.yb[:,self.n_skip:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SkipNaNCallback(Callback):\n",
    "    \"`Callback` skips minibatches with a NaN loss\"\n",
    "    def after_loss(self): \n",
    "#         import pdb;pdb.set_trace()\n",
    "        if torch.isnan(self.learn.loss):\n",
    "            self.opt.zero_grad()\n",
    "            raise CancelBatchException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CancelNaNCallback(Callback):\n",
    "    \"`Callback` cancels trainig minibatches with a NaN loss\"\n",
    "    def after_loss(self): \n",
    "        if torch.isnan(self.learn.loss):\n",
    "            raise CancelTrainException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class VarySeqLen(Callback):\n",
    "    \"`Callback` varies sequence length of every mini batch\"\n",
    "    def __init__(self, min_len = 50):\n",
    "        self.min_len = min_len\n",
    "\n",
    "    def before_batch(self):\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "        #         import pdb; pdb.set_trace()\n",
    "                lx = self.xb[0].shape[1]\n",
    "                ly = self.yb[0].shape[1]\n",
    "                lim = random.randint(self.min_len,ly)\n",
    "        #         import pdb; pdb.set_trace()\n",
    "                if ly < lx:\n",
    "                    self.learn.xb = tuple([x[:,:-(ly-lim)] for x in self.xb])\n",
    "                else:\n",
    "                    self.learn.xb = tuple([x[:,:lim] for x in self.xb])\n",
    "                    \n",
    "                self.learn.yb = tuple([y[:,:lim] for y in self.yb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.849715</td>\n",
       "      <td>11.860315</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SimpleRNN(2,1)\n",
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=VarySeqLen(10)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.callback.all import *\n",
    "class CB_TruncateSequence(Callback):\n",
    "    \"`Callback` varies sequence length of every mini batch\"\n",
    "    def __init__(self, truncate_length = 50,scheduler=sched_lin):\n",
    "        self._truncate_length = truncate_length\n",
    "        self._scheduler = scheduler\n",
    "\n",
    "    def before_batch(self):\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "        #         import pdb; pdb.set_trace()\n",
    "                lx = self.xb[0].shape[1]\n",
    "                ly = self.yb[0].shape[1]\n",
    "                lim = int(self._scheduler(ly-self._truncate_length,0,self.pct_train))\n",
    "                if lim>0:\n",
    "                    # print(lx,ly,lim)\n",
    "            #         import pdb; pdb.set_trace()\n",
    "                    self.learn.xb = tuple([x[:,:-lim] for x in self.xb])\n",
    "                    self.learn.yb = tuple([y[:,:-lim] for y in self.yb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sched_lin_p(start, end, pos, p=0.75): \n",
    "    return end if pos >= p else start + pos/p*(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sched_ramp(start, end, pos, p_left=0.1, p_right=0.5):\n",
    "    if pos >= p_right: \n",
    "        return end\n",
    "    elif pos <= p_left: \n",
    "        return start\n",
    "    else: \n",
    "        return start + (end - start) * (pos - p_left) / (p_right - p_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_sz = 200\n",
    "pred_sz = 600\n",
    "win_sz = init_sz+pred_sz\n",
    "truncate_length = init_sz+10\n",
    "plt.figure()\n",
    "plt.plot([win_sz-sched_lin_p(win_sz-truncate_length,0,pct) for pct in np.linspace(0,1,100)])\n",
    "plt.plot([win_sz-sched_ramp(win_sz-truncate_length,0,pct,0.2,0.6) for pct in np.linspace(0,1,100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.096995</td>\n",
       "      <td>11.057790</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SimpleRNN(2,1)\n",
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=CB_TruncateSequence(50,sched_lin_p)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CB_AddLoss(Callback):\n",
    "    '''Callback that adds the results of a given loss_function to the mini_batch after the original loss function has been applied'''\n",
    "    def __init__(self,_loss_func,alpha=1.0):\n",
    "        self._loss_func = _loss_func\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def after_loss(self):\n",
    "        if not self.training: return\n",
    "\n",
    "        loss = self.alpha * self._loss_func(self.pred,self.y)\n",
    "        self.learn.loss_grad = loss + self.learn.loss_grad\n",
    "        self.learn.loss = loss + self.learn.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>150.906937</td>\n",
       "      <td>12.781384</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SimpleRNN(2,1)\n",
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=CB_AddLoss(nn.MSELoss(),alpha=10)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class BatchLossFilter(Callback):\n",
    "#     \"\"\" \n",
    "#     Callback that selects the hardest samples in every batch representing a percentage of the total loss.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, loss_perc=1., filter_criterion=nn.HuberLoss(reduction='none'), schedule_func:Optional[callable]=None):\n",
    "#         store_attr()  # Stores all passed arguments as class attributes\n",
    "\n",
    "#     def before_batch(self):\n",
    "#         \"\"\"\n",
    "#         Selects hardest samples before processing each batch.\n",
    "#         \"\"\"\n",
    "#         if not self.training: return  # Skip if not in training mode\n",
    "#         if self.schedule_func is None: loss_perc = self.loss_perc\n",
    "#         else: loss_perc = self.loss_perc * self.schedule_func(self.pct_train)  # Adjust loss_perc if a schedule function is given\n",
    "#         if loss_perc == 1.: return  # If loss_perc is 1, all samples are included, no need to filter\n",
    "\n",
    "#         with torch.no_grad():  # No gradients needed for the filtering operation\n",
    "#             losses = self.filter_criterion(self.learn.model(self.x), self.y)  # Compute individual losses\n",
    "#             if losses.ndim >= 2: losses = losses.mean(tuple(range(1,losses.ndim)))  # If loss is multi-dimensional, take the mean over all but the first dimension\n",
    "#             losses /= losses.sum()  # Normalize losses to make them sum up to 1\n",
    "            \n",
    "#             idxs = torch.argsort(losses, descending=True)  # Sort indices by loss\n",
    "#             cut_idx = max(1, torch.argmax((losses[idxs].cumsum(0) > loss_perc).float()))  # Determine the cut-off index where cumulative sum exceeds loss_perc\n",
    "#             idxs = idxs[:cut_idx]  # Select the hardest samples\n",
    "\n",
    "#             self.learn.xb = tuple(xbi[idxs] for xbi in self.learn.xb)  # Filter the input batch\n",
    "#             self.learn.yb = tuple(ybi[idxs] for ybi in self.learn.yb)  # Filter the output batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BatchLossFilter(Callback):\n",
    "    \"\"\" \n",
    "    Callback that selects the hardest samples in every batch representing a percentage of the total loss.\n",
    "    \"\"\"\n",
    "    def __init__(self, loss_perc=1., filter_criterion=nn.HuberLoss(reduction='none'), schedule_func:Optional[callable]=None):\n",
    "        store_attr() \n",
    "\n",
    "    def after_pred(self):\n",
    "        \"\"\"\n",
    "        Selects hardest samples after model prediction and before loss computation.\n",
    "        \"\"\"\n",
    "        if not self.training: return  # Skip if not in training mode\n",
    "        if self.schedule_func is None: loss_perc = self.loss_perc\n",
    "        else: loss_perc = self.loss_perc * self.schedule_func(self.pct_train)  # Adjust loss_perc if a schedule function is given\n",
    "        if loss_perc == 1.: return  # If loss_perc is 1, all samples are included, no need to filter\n",
    "\n",
    "        with torch.no_grad():  # No gradients needed for the filtering operation\n",
    "            losses = self.filter_criterion(self.pred, self.y)  # Compute individual losses with model's predictions\n",
    "            if losses.ndim >= 2: losses = losses.mean(tuple(range(1,losses.ndim)))  # If loss is multi-dimensional, take the mean over all but the first dimension\n",
    "            losses /= losses.sum()  # Normalize losses to make them sum up to 1\n",
    "            \n",
    "            idxs = torch.argsort(losses, descending=True)  # Sort indices by loss\n",
    "            cut_idx = max(1, torch.argmax((losses[idxs].cumsum(0) > loss_perc).float()))  # Determine the cut-off index where cumulative sum exceeds loss_perc\n",
    "            idxs = idxs[:cut_idx]  # Select the hardest samples\n",
    "\n",
    "        self.learn.xb = tuple(xbi[idxs] for xbi in self.learn.xb)  # Filter the input batch\n",
    "        self.learn.yb = tuple(ybi[idxs] for ybi in self.learn.yb)  # Filter the output batch\n",
    "        self.learn.pred = self.pred[idxs]  # Update the predictions to match the filtered batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class BatchLossFilter(Callback):\n",
    "#     \"\"\" \n",
    "#     Callback that selects the hardest samples in every batch representing a percentage of the total loss.\n",
    "#     \"\"\"\n",
    "#     order = -9\n",
    "#     def __init__(self, loss_perc=1., filter_criterion=nn.HuberLoss(reduction='none'), schedule_func:Optional[callable]=None):\n",
    "#         store_attr() \n",
    "\n",
    "#     def after_pred(self):\n",
    "#         \"\"\"\n",
    "#         Calculate losses and select hardest samples after model prediction and before loss computation.\n",
    "#         \"\"\"\n",
    "#         if not self.training: return  # Skip if not in training mode\n",
    "#         if self.schedule_func is None: loss_perc = self.loss_perc\n",
    "#         else: loss_perc = self.loss_perc * self.schedule_func(self.pct_train)  # Adjust loss_perc if a schedule function is given\n",
    "#         if loss_perc == 1.: return  # If loss_perc is 1, all samples are included, no need to filter\n",
    "\n",
    "#         with torch.no_grad():  # No gradients needed for the filtering operation\n",
    "#             losses = self.filter_criterion(self.pred, *self.learn.yb)  # Compute individual losses with model's predictions\n",
    "#             if losses.ndim >= 2: losses = losses.mean(tuple(range(1,losses.ndim)))  # If loss is multi-dimensional, take the mean over all but the first dimension\n",
    "#             losses /= losses.sum()  # Normalize losses to make them sum up to 1\n",
    "            \n",
    "#             idxs = torch.argsort(losses, descending=True)  # Sort indices by loss\n",
    "#             cut_idx = max(1, torch.argmax((losses[idxs].cumsum(0) > loss_perc).float()))  # Determine the cut-off index where cumulative sum exceeds loss_perc\n",
    "#             self.idxs = idxs[:cut_idx]  # Store the indices of the hardest samples\n",
    "\n",
    "#     def after_loss(self):\n",
    "#         \"\"\"\n",
    "#         Recalculate the loss with the selected hardest samples.\n",
    "#         \"\"\"\n",
    "#         if not self.training: return  # Skip if not in training mode\n",
    "#         self.learn.loss_grad = self.loss_func(self.pred[self.idxs], *(yb[self.idxs] for yb in self.learn.yb))  # Compute the loss with hardest samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13.381271</td>\n",
       "      <td>11.284644</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11.856389</td>\n",
       "      <td>7.403503</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.774568</td>\n",
       "      <td>0.969172</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.467852</td>\n",
       "      <td>0.524334</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.854975</td>\n",
       "      <td>0.267916</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.806578</td>\n",
       "      <td>0.255146</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.036611</td>\n",
       "      <td>0.162158</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.474755</td>\n",
       "      <td>0.139504</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.034573</td>\n",
       "      <td>0.129666</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.689114</td>\n",
       "      <td>0.103635</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SimpleRNN(2,1)\n",
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=BatchLossFilter(loss_perc=0.8)).fit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.callback.hook import *\n",
    "@delegates()\n",
    "class TimeSeriesRegularizer(HookCallback):\n",
    "    \"Callback that adds AR and TAR to the loss, calculated by output of provided layer\"\n",
    "    run_before=TrainEvalCallback\n",
    "    def __init__(self,alpha=0.0, beta=0.0,dim = None,detach=False, **kwargs):\n",
    "        if 'modules' not in kwargs: print('Warning: No module was provided to TimeSerieRegularizer')\n",
    "        super().__init__(detach=detach,**kwargs)\n",
    "        store_attr('alpha,beta,dim')\n",
    "        \n",
    "    def hook(self, m, i, o): \n",
    "#         import pdb; pdb.set_trace()\n",
    "        if isinstance(o,torch.Tensor):\n",
    "            self.out = o\n",
    "        else:\n",
    "            self.out = o[0]\n",
    "        \n",
    "        #find time axis if not already provided\n",
    "        if self.dim is None:\n",
    "            self.dim = np.argmax([0,self.out.shape[1],self.out.shape[2]])\n",
    "    \n",
    "    def after_loss(self):\n",
    "        if not self.training: return\n",
    "        \n",
    "        h = self.out.float()\n",
    "        \n",
    "        if self.alpha != 0.:  \n",
    "            l_a = float(self.alpha) * h.pow(2).mean()\n",
    "            self.learn.loss_grad += l_a \n",
    "            \n",
    "        if self.beta != 0. and h.shape[self.dim]>1:\n",
    "            h_diff = (h[:,1:] - h[:,:-1]) if self.dim == 1 else (h[:,:,1:] - h[:,:,:-1])\n",
    "            l_b = float(self.beta) * h_diff.pow(2).mean()\n",
    "            self.learn.loss_grad += l_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No module was provided to TimeSerieRegularizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pheenix/miniconda3/envs/env_fastai/lib/python3.10/site-packages/fastai/callback/core.py:69: UserWarning: You are shadowing an attribute (modules) that exists in the learner. Use `self.learn.modules` to avoid this\n",
      "  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.580891</td>\n",
       "      <td>4.955561</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=[TimeSeriesRegularizer(1.0,1.2)]).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ARInitCB(Callback):\n",
    "    '''Adds the target variable to the input tuple for autoregression'''\n",
    "    def before_batch(self):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        self.learn.xb = tuple([*self.xb,*self.yb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.766001</td>\n",
       "      <td>0.101908</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss()).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from matplotlib.lines import Line2D\n",
    "def plot_grad_flow(named_parameters):\n",
    "    '''Plots the gradients flowing through different layers in the net during training.\n",
    "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "    *modified version of https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063/8*\n",
    "    \n",
    "    Call multiple time for transparent overlays, representing the mean gradients\n",
    "    '''\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "#             pdb.set_trace()\n",
    "            ave_grads.append(0 if p.grad is None else p.grad.abs().mean().cpu())\n",
    "            max_grads.append(0 if p.grad is None else p.grad.abs().max().cpu())\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"Gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.yscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "                Line2D([0], [0], color=\"b\", lw=4),\n",
    "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class CB_PlotGradient(Callback):\n",
    "    '''Plot the Gradient Distribution for every trainable parameter'''\n",
    "    \n",
    "    def __init__(self, n_draws=20): self.n_draws = n_draws\n",
    "    \n",
    "    def begin_fit(self):\n",
    "        '''Create a new figure to plot in'''\n",
    "        plt.figure()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    def after_backward(self):\n",
    "        '''plot the gradient for every layer of the current minibatch'''\n",
    "        # plotting n_draws times at the whole training\n",
    "        if self.iter % (max(self.n_epoch*self.n_iter//self.n_draws,1)) == 0:\n",
    "#         if self.iter == self.n_iter-1:\n",
    "            plot_grad_flow(self.learn.model.named_parameters())\n",
    "#             print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.083577</td>\n",
       "      <td>0.068726</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=CB_PlotGradient()).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import functools\n",
    "\n",
    "def ignore_nan(func):\n",
    "    '''remove nan values from tensors before function execution, reduces tensor to a flat array, apply to functions such as mse'''\n",
    "    @functools.wraps(func)\n",
    "    def ignore_nan_decorator(*args, **kwargs):\n",
    "#         mask = ~torch.isnan(args[-1]) #nan mask of target tensor\n",
    "#         args = tuple([x[mask] for x in args]) #remove nan values\n",
    "        mask = ~torch.isnan(args[-1][...,-1]) #nan mask of target tensor\n",
    "        args = tuple([x[mask,:] for x in args]) #remove nan values\n",
    "        return func(*args, **kwargs)\n",
    "    return ignore_nan_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "y_t = torch.ones(32,n,6)\n",
    "y_t[:,20]=np.nan\n",
    "y_p = torch.ones(32,n,6)*1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1000, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(~torch.isnan(y_t)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1000, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.isnan(mse(y_p,y_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "mse_nan = ignore_nan(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(mse_nan(y_p,y_t),0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import functools\n",
    "\n",
    "def float64_func(func):\n",
    "    '''calculate function internally with float64 and convert the result back'''\n",
    "    @functools.wraps(func)\n",
    "    def float64_func_decorator(*args, **kwargs):\n",
    "        typ = args[0].dtype\n",
    "        args = tuple([x.double() if issubclass(type(x),Tensor ) else x for x in args]) #remove nan values\n",
    "        return func(*args, **kwargs).type(typ)\n",
    "    return float64_func_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.067331</td>\n",
       "      <td>0.060953</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=float64_func(nn.MSELoss())).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def SkipNLoss(fn,n_skip=0):\n",
    "    '''Loss-Function modifier that skips the first n samples of sequential data'''\n",
    "    @functools.wraps(fn)\n",
    "    def _inner( input, target):\n",
    "        return fn(input[:,n_skip:],target[:,n_skip:])\n",
    "    \n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.019123</td>\n",
       "      <td>0.014104</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=SkipNLoss(nn.MSELoss(),n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def CutLoss(fn,l_cut=0,r_cut=None):\n",
    "    '''Loss-Function modifier that skips the first n samples of sequential data'''\n",
    "    @functools.wraps(fn)\n",
    "    def _inner( input, target):\n",
    "        return fn(input[:,l_cut:r_cut],target[:,l_cut:r_cut])\n",
    "    \n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.019676</td>\n",
       "      <td>0.015483</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=CutLoss(nn.MSELoss(),l_cut=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def weighted_mae(input, target):\n",
    "    max_weight = 1.0\n",
    "    min_weight = 0.1\n",
    "    seq_len = input.shape[1]\n",
    "    weights = torch.logspace(start=torch.log10(torch.tensor(max_weight)),\n",
    "                             end=torch.log10(torch.tensor(min_weight)),\n",
    "                             steps=seq_len,device=input.device)\n",
    "    weights = (weights / weights.sum())[None,:,None]\n",
    "\n",
    "    return ((input-target).abs()*weights).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.109405</td>\n",
       "      <td>0.100580</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=SkipNLoss(weighted_mae,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def RandSeqLenLoss(fn,min_idx=1,max_idx=None,mid_idx=None):\n",
    "    '''Loss-Function modifier that truncates the sequence length of every sequence in the minibatch inidiviually randomly.\n",
    "    At the moment slow for very big batchsizes.'''\n",
    "    @functools.wraps(fn)\n",
    "    def _inner( input, target):\n",
    "        bs,l,_ = input.shape\n",
    "        if 'max_idx' not in locals():  max_idx = l\n",
    "        if 'mid_idx' not in locals():  mid_idx = min_idx#+(max_idx-min_idx)//4\n",
    "        # len_list = torch.randint(min_idx,max_idx,(bs,))\n",
    "        len_list = np.random.triangular(min_idx,mid_idx,max_idx,(bs,)).astype(int)\n",
    "        return torch.stack([fn(input[i,:len_list[i]],target[i,:len_list[i]]) for i in range(bs)]).mean()\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.349276</td>\n",
       "      <td>0.280791</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=RandSeqLenLoss(nn.MSELoss())).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fun_rmse(inp, targ): \n",
    "    '''rmse loss function defined as a function not as a AccumMetric'''\n",
    "    return torch.sqrt(F.mse_loss(inp, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.043738</td>\n",
       "      <td>0.039516</td>\n",
       "      <td>0.101812</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),metrics=SkipNLoss(fun_rmse,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cos_sim_loss(inp, targ): \n",
    "    '''rmse loss function defined as a function not as a AccumMetric'''\n",
    "    return (1-F.cosine_similarity(inp,targ,dim=-1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.102246</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=cos_sim_loss,metrics=SkipNLoss(fun_rmse,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cos_sim_loss_pow(inp, targ): \n",
    "    '''rmse loss function defined as a function not as a AccumMetric'''\n",
    "    return (1-F.cosine_similarity(inp,targ,dim=-1)).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.102680</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=cos_sim_loss_pow,metrics=SkipNLoss(fun_rmse,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def nrmse(inp, targ): \n",
    "    '''rmse loss function scaled by variance of each target variable'''\n",
    "    mse = (inp-targ).pow(2).mean(dim=[0,1])\n",
    "    var = targ.var(dim=[0,1])\n",
    "    return (mse/var).sqrt().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1000, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.one_batch()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>nrmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.037912</td>\n",
       "      <td>0.031866</td>\n",
       "      <td>0.269171</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),metrics=SkipNLoss(nrmse,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def nrmse_std(inp, targ): \n",
    "    '''rmse loss function scaled by standard deviation of each target variable'''\n",
    "    mse = (inp-targ).pow(2).mean(dim=[0,1])\n",
    "    var = targ.std(dim=[0,1])\n",
    "    return (mse/var).sqrt().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>nrmse_std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.035721</td>\n",
       "      <td>0.033442</td>\n",
       "      <td>0.172699</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),metrics=SkipNLoss(nrmse_std,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mean_vaf(inp,targ):\n",
    "    return (1-((targ-inp).var()/targ.var()))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_vaf</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.032143</td>\n",
       "      <td>0.029042</td>\n",
       "      <td>98.099419</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),metrics=SkipNLoss(mean_vaf,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Learner Models\n",
    "Create Learner with different kinds of models with fitting Parameters and regularizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_inp_out_size(db):\n",
    "    '''returns input and output size of a timeseries databunch'''\n",
    "    tup = db.one_batch()\n",
    "    inp = tup[0].shape[-1]\n",
    "    out = tup[1].shape[-1]\n",
    "    return inp,out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_inp_out_size(db),(2,1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Learner\n",
    "The Learners include model specific optimizations. Removing the first n_skip samples of the loss function of transient time, greatly improves training stability. In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(SimpleRNN, keep=True)\n",
    "def RNNLearner(db,loss_func=nn.MSELoss(),metrics=[fun_rmse],n_skip=0,cbs=None,**kwargs):\n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = SimpleRNN(inp,out,**kwargs)\n",
    "  \n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "        \n",
    "    metrics= [skip(f) for f in metrics]\n",
    "    loss_func = skip(loss_func)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=loss_func,opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.899495</td>\n",
       "      <td>12.990510</td>\n",
       "      <td>3.592842</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RNNLearner(db,rnn_type='gru').fit(1,1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCN Learner\n",
    "Performs better on multi input data. Higher beta values allow a way smoother prediction. Way faster then RNNs in prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(TCN, keep=True)\n",
    "def TCNLearner(db,hl_depth=3,loss_func=nn.MSELoss(),metrics=[fun_rmse],n_skip=0,cbs=None,**kwargs):\n",
    "    inp,out = get_inp_out_size(db)\n",
    "    n_skip = 2**hl_depth if n_skip is None else n_skip\n",
    "    model = TCN(inp,out,hl_depth,**kwargs)\n",
    "  \n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "        \n",
    "    metrics= [skip(f) for f in metrics]\n",
    "    loss_func = skip(loss_func)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=loss_func,opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13.229624</td>\n",
       "      <td>13.264530</td>\n",
       "      <td>3.612698</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TCNLearner(db).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRNN Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(CRNN, keep=True)\n",
    "def CRNNLearner(db,loss_func=nn.MSELoss(),metrics=[fun_rmse],n_skip=0,cbs=None,**kwargs):\n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = CRNN(inp,out,**kwargs)\n",
    "  \n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "        \n",
    "    metrics= [skip(f) for f in metrics]\n",
    "    loss_func = skip(loss_func)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=loss_func,opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.140131</td>\n",
       "      <td>6.105537</td>\n",
       "      <td>2.454662</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CRNNLearner(db,rnn_type='gru').fit(1,3e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(TCN, keep=True)\n",
    "def AR_TCNLearner(db,hl_depth=3,alpha=1,beta=1,early_stop=0,metrics=None,n_skip=None,**kwargs):\n",
    "    n_skip = 2**hl_depth if n_skip is None else n_skip\n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "    \n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = AR_Model(TCN(inp+out,out,hl_depth,**kwargs),ar=False,rf=n_skip)\n",
    "    model.init_normalize(db.one_batch())\n",
    "    \n",
    "    cbs=[ARInitCB(),TimeSeriesRegularizer(alpha=alpha,beta=beta,modules=[model.model.conv_layers[-1]]),SaveModelCallback()]\n",
    "    if early_stop > 0:\n",
    "        cbs += [EarlyStoppingCallback(patience=early_stop)]\n",
    "        \n",
    "    if metrics is None: metrics=SkipNLoss(fun_rmse,n_skip)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=nn.MSELoss(),opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(SimpleRNN, keep=True)\n",
    "def AR_RNNLearner(db,alpha=0,beta=0,early_stop=0,metrics=None,n_skip=0,fname='model',**kwargs):\n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "    \n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = AR_Model(SimpleRNN(inp+out,out,**kwargs),ar=False,hs=True)\n",
    "    model.init_normalize(db.one_batch())\n",
    "    \n",
    "    cbs=[ARInitCB(),TimeSeriesRegularizer(alpha=alpha,beta=beta,modules=[model.model.rnn]),SaveModelCallback()]\n",
    "    if early_stop > 0:\n",
    "        cbs += [EarlyStoppingCallback(patience=early_stop)]\n",
    "        \n",
    "    if metrics is None: metrics=SkipNLoss(fun_rmse,n_skip)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=nn.MSELoss(),opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
